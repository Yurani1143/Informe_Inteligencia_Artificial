{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Árboles de decisiones para predecir si una persona sufrirá de un derrame cerebral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Leer el archivo stroke.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------\n",
    "# Se importan las librerias\n",
    "#----------------------------------------------------------\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 700 entries, 0 to 699\n",
      "Data columns (total 11 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   sexo                    700 non-null    object \n",
      " 1   edad                    700 non-null    float64\n",
      " 2   hipertension            700 non-null    int64  \n",
      " 3   enfermedades_cardiacas  700 non-null    int64  \n",
      " 4   casado                  700 non-null    object \n",
      " 5   tipo_trabajo            700 non-null    object \n",
      " 6   tipo_residencia         700 non-null    object \n",
      " 7   nivel_glucosa_promedio  700 non-null    float64\n",
      " 8   indice_masa_corporal    651 non-null    float64\n",
      " 9   estado_tabaquismo       700 non-null    object \n",
      " 10  derrame_cerebral        700 non-null    int64  \n",
      "dtypes: float64(3), int64(3), object(5)\n",
      "memory usage: 60.3+ KB\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------------------------\n",
    "# Url de los datos\n",
    "#----------------------------------------------------------\n",
    "\n",
    "url = (\"https://raw.githubusercontent.com/Yurani1143/Informe_Inteligencia_Artificial/main/stroke.csv\")\n",
    "\n",
    "#----------------------------------------------------------\n",
    "# Se cargan los datos\n",
    "#----------------------------------------------------------\n",
    "datos = pd.read_csv(url, sep=\",\")\n",
    "datos.columns= [\"sexo\",\"edad\",\"hipertension\",\"enfermedades_cardiacas\",\"casado\",\"tipo_trabajo\",\"tipo_residencia\",\"nivel_glucosa_promedio\",\"indice_masa_corporal\",\"estado_tabaquismo\",\"derrame_cerebral\"]\n",
    "datos.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Seleccionar aleatoriamente el 80% del conjunto de datos para entrenar y el 20% restante para las pruebas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700 560 140\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------------------------\n",
    "# Libreria sklearn\n",
    "#----------------------------------------------------------\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "N=len(datos) # cantidad de datos\n",
    "cTrain=int(N*0.8) # 80% para entrenar y 20% para probar\n",
    "cTest=N-cTrain \n",
    "\n",
    "print(N,cTrain,cTest)# cantidad de: datos completos, datos entrenados, datos para probar\n",
    "\n",
    "train_data,test_data= sklearn.model_selection.train_test_split(datos, train_size=cTrain, test_size=cTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "700 es el número de observaciones en la base de datos\n",
    "\n",
    "560 es el 80% de las observaciones de la base de datos que se van a utilizar para entrenar los datos\n",
    "\n",
    "140 es el 20% de las observaciones de la base de datos que se van a utilizar para probar el modelo de predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(560, 11)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#----------------------------------------------------------\n",
    "# Dimensiones de los datos de entrenamiento\n",
    "#----------------------------------------------------------\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Utilizar una estrategia para normalizar los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline para los atributos categóricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------\n",
    "#Librerias sklearn\n",
    "#----------------------------------------------------------\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# 5 atributos categóricos\n",
    "cat_attribs = ['sexo','casado','tipo_trabajo','tipo_residencia','estado_tabaquismo']\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"cat_encoder\", OneHotEncoder(sparse=False))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline para los atributos númericos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 5 atributos numéricos\n",
    "num_attribs = ['edad','hipertension','enfermedades_cardiacas','nivel_glucosa_promedio','indice_masa_corporal']\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------\n",
    "#Libreria sklearn\n",
    "#----------------------------------------------------------\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "    (\"num\", num_pipeline, num_attribs),\n",
    "    (\"cat\", cat_pipeline, cat_attribs),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Acer\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(560, 20)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#----------------------------------------------------------\n",
    "# Se transforman los datos entrenados \n",
    "# Variables independientes\n",
    "#----------------------------------------------------------\n",
    "X_train = full_pipeline.fit_transform(train_data)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.09198841, -0.4259514 , -0.33333333, -0.47079252, -1.02296967,\n",
       "        1.        ,  0.        ,  0.        ,  1.        ,  0.        ,\n",
       "        0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
       "        1.        ,  0.        ,  0.        ,  1.        ,  0.        ])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "650    0\n",
       "278    0\n",
       "153    1\n",
       "595    0\n",
       "248    1\n",
       "      ..\n",
       "359    0\n",
       "124    1\n",
       "412    0\n",
       "136    1\n",
       "130    1\n",
       "Name: derrame_cerebral, Length: 560, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#----------------------------------------------------------\n",
    "# Variable dependiente -> derrame_cerebral\n",
    "#----------------------------------------------------------\n",
    "\n",
    "y_train = train_data[\"derrame_cerebral\"]\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.3438782 , -0.4259514 , -0.33333333, ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       [-0.13236575, -0.4259514 , -0.33333333, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [ 0.63043839, -0.4259514 , -0.33333333, ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 0.09198841, -0.4259514 , -0.33333333, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [-1.79258651, -0.4259514 , -0.33333333, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.2266009 ,  2.34768565, -0.33333333, ...,  0.        ,\n",
       "         1.        ,  0.        ]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#----------------------------------------------------------\n",
    "# Se transforman los datos de prueba \n",
    "# Variables independientes\n",
    "#--------------------------------------------------------\n",
    "X_test = full_pipeline.transform(test_data) \n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "440    0\n",
       "648    0\n",
       "240    1\n",
       "399    0\n",
       "121    1\n",
       "      ..\n",
       "477    0\n",
       "414    0\n",
       "107    1\n",
       "421    0\n",
       "148    1\n",
       "Name: derrame_cerebral, Length: 140, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#----------------------------------------------------------\n",
    "# Variable dependiente -> derrame_cerebral\n",
    "#----------------------------------------------------------\n",
    "y_test = test_data[\"derrame_cerebral\"]\n",
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Configurar los hiperparámetros del árbol de decisión de la siguiente manera: criterion=gini, splitter=best, y random_state=123. Obtener 10 árboles de decisión que resultan de modificar el hiperparámetro max_depth desde 5 hasta 50 con incrementos de 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "Puntajes de la validación cruzada:\n",
      "[0.72321429 0.75892857 0.74107143 0.75       0.71428571]\n",
      "Promedio de los puntajes con max_depth=5 -> 0.7375\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Puntajes de la validación cruzada:\n",
      "[0.64285714 0.72321429 0.67857143 0.76785714 0.69642857]\n",
      "Promedio de los puntajes con max_depth=10 -> 0.7018\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Puntajes de la validación cruzada:\n",
      "[0.66071429 0.6875     0.67857143 0.73214286 0.70535714]\n",
      "Promedio de los puntajes con max_depth=15 -> 0.6929\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Puntajes de la validación cruzada:\n",
      "[0.66071429 0.6875     0.67857143 0.73214286 0.70535714]\n",
      "Promedio de los puntajes con max_depth=20 -> 0.6929\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Puntajes de la validación cruzada:\n",
      "[0.66071429 0.6875     0.67857143 0.73214286 0.70535714]\n",
      "Promedio de los puntajes con max_depth=25 -> 0.6929\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Puntajes de la validación cruzada:\n",
      "[0.66071429 0.6875     0.67857143 0.73214286 0.70535714]\n",
      "Promedio de los puntajes con max_depth=30 -> 0.6929\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Puntajes de la validación cruzada:\n",
      "[0.66071429 0.6875     0.67857143 0.73214286 0.70535714]\n",
      "Promedio de los puntajes con max_depth=35 -> 0.6929\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Puntajes de la validación cruzada:\n",
      "[0.66071429 0.6875     0.67857143 0.73214286 0.70535714]\n",
      "Promedio de los puntajes con max_depth=40 -> 0.6929\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Puntajes de la validación cruzada:\n",
      "[0.66071429 0.6875     0.67857143 0.73214286 0.70535714]\n",
      "Promedio de los puntajes con max_depth=45 -> 0.6929\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Puntajes de la validación cruzada:\n",
      "[0.66071429 0.6875     0.67857143 0.73214286 0.70535714]\n",
      "Promedio de los puntajes con max_depth=50 -> 0.6929\n",
      "----------------------------------\n",
      "Los hiperparámetros del árbol con mayor precisión son:\n",
      "max_depth: 5\n",
      "criterion: gini\n",
      "splitter: best\n",
      "random_state: 123\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------------------------\n",
    "#Librerias sklearn.tree y sklearn.model_selection\n",
    "#----------------------------------------------------------\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "scores=[]\n",
    "scor=[]\n",
    "decision_tree = []\n",
    "accuracies = []\n",
    "max_depths = range(5, 55, 5)\n",
    "\n",
    "for max_depth in max_depths: \n",
    "    model_tree = DecisionTreeClassifier(criterion=\"gini\", splitter=\"best\", max_depth=max_depth, random_state=123)\n",
    "    model_tree.fit(X_train, y_train)\n",
    "    y_pred = model_tree.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred) \n",
    "    accuracies.append(accuracy)\n",
    "    decision_tree.append(model_tree.score(X_test, y_test))\n",
    "    scores = cross_val_score(model_tree, X_train, y_train, cv=5,scoring='accuracy') \n",
    "    scor.append(scores.mean()) \n",
    "    print(\"----------------------------------\")\n",
    "    print(\"Puntajes de la validación cruzada:\")\n",
    "    print(scores)\n",
    "    print(f\"Promedio de los puntajes con max_depth={max_depth}\",\"->\" ,round(scores.mean(),4))\n",
    "    print(\"----------------------------------\")\n",
    "    \n",
    "#----------------------------------------------------------   \n",
    "# El índice del árbol con mayor exactitud\n",
    "best_tree_index = np.argmax(scor)\n",
    "#----------------------------------------------------------\n",
    "\n",
    "#----------------------------------------------------------\n",
    "# Se imprime los hiperparámetros del árbol con mayor precisión\n",
    "print(\"Los hiperparámetros del árbol con mayor precisión son:\")\n",
    "print(\"max_depth:\", max_depths[best_tree_index])\n",
    "print(\"criterion: gini\")\n",
    "print(\"splitter: best\")\n",
    "print(\"random_state: 123\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Incluya en el notebook una tabla con el accuracy para los 10 árboles del punto anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.737500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>0.701786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>0.692857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>0.692857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>0.692857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30</td>\n",
       "      <td>0.692857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>35</td>\n",
       "      <td>0.692857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>40</td>\n",
       "      <td>0.692857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>45</td>\n",
       "      <td>0.692857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>50</td>\n",
       "      <td>0.692857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_depth  accuracy\n",
       "0          5  0.737500\n",
       "1         10  0.701786\n",
       "2         15  0.692857\n",
       "3         20  0.692857\n",
       "4         25  0.692857\n",
       "5         30  0.692857\n",
       "6         35  0.692857\n",
       "7         40  0.692857\n",
       "8         45  0.692857\n",
       "9         50  0.692857"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#----------------------------------------------------------\n",
    "#Libreria pandas\n",
    "#----------------------------------------------------------\n",
    "import pandas as pd\n",
    "\n",
    "# Mostrar el accuracy de los 10 arboles construidos\n",
    "accuracies_CV = pd.DataFrame({\"max_depth\": range(5, 55, 5), \"accuracy\": scor})\n",
    "display(accuracies_CV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Repita el mismo procedimiento del punto 4 usando como hiperparámetros criterion=entropy, splitter=best, random_state=123, y variando el hiperparámetro max_depth desde 5 hasta 50 con incrementos de 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "Puntajes de la validación cruzada:\n",
      "[0.75892857 0.77678571 0.71428571 0.75       0.73214286]\n",
      "Promedio de los puntajes con max_depth=5 -> 0.7464\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Puntajes de la validación cruzada:\n",
      "[0.70535714 0.72321429 0.66964286 0.72321429 0.72321429]\n",
      "Promedio de los puntajes con max_depth=10 -> 0.7089\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Puntajes de la validación cruzada:\n",
      "[0.65178571 0.6875     0.65178571 0.6875     0.72321429]\n",
      "Promedio de los puntajes con max_depth=15 -> 0.6804\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Puntajes de la validación cruzada:\n",
      "[0.66071429 0.6875     0.66071429 0.69642857 0.73214286]\n",
      "Promedio de los puntajes con max_depth=20 -> 0.6875\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Puntajes de la validación cruzada:\n",
      "[0.66071429 0.6875     0.66071429 0.69642857 0.73214286]\n",
      "Promedio de los puntajes con max_depth=25 -> 0.6875\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Puntajes de la validación cruzada:\n",
      "[0.66071429 0.6875     0.66071429 0.69642857 0.73214286]\n",
      "Promedio de los puntajes con max_depth=30 -> 0.6875\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Puntajes de la validación cruzada:\n",
      "[0.66071429 0.6875     0.66071429 0.69642857 0.73214286]\n",
      "Promedio de los puntajes con max_depth=35 -> 0.6875\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Puntajes de la validación cruzada:\n",
      "[0.66071429 0.6875     0.66071429 0.69642857 0.73214286]\n",
      "Promedio de los puntajes con max_depth=40 -> 0.6875\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Puntajes de la validación cruzada:\n",
      "[0.66071429 0.6875     0.66071429 0.69642857 0.73214286]\n",
      "Promedio de los puntajes con max_depth=45 -> 0.6875\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Puntajes de la validación cruzada:\n",
      "[0.66071429 0.6875     0.66071429 0.69642857 0.73214286]\n",
      "Promedio de los puntajes con max_depth=50 -> 0.6875\n",
      "----------------------------------\n",
      "Los hiperparámetros del árbol con mayor precisión son:\n",
      "max_depth: 5\n",
      "criterion: entropy\n",
      "splitter: best\n",
      "random_state: 123\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------------------------\n",
    "#Librerias sklearn.tree y sklearn.model_selection\n",
    "#----------------------------------------------------------\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "scores_2=[]\n",
    "scor_2 =[]\n",
    "decision_tree_2 = []\n",
    "accuracies_7= []\n",
    "max_depths = range(5, 55, 5)\n",
    "\n",
    "for max_depth in max_depths: \n",
    "    model_tree_2 = DecisionTreeClassifier(criterion=\"entropy\", splitter=\"best\", max_depth=max_depth, random_state=123)\n",
    "    model_tree_2.fit(X_train, y_train)\n",
    "    accuracy_7 = accuracy_score(y_test, y_pred) # exactitud de cada árbol\n",
    "    accuracies_7.append(accuracy_7)\n",
    "    decision_tree_2.append(model_tree_2.score(X_test, y_test))\n",
    "    scores_2 = cross_val_score(model_tree_2, X_train, y_train, cv=5,scoring='accuracy')\n",
    "    scor_2.append(scores_2.mean()) # promedio de los scores\n",
    "    print(\"----------------------------------\")\n",
    "    print(\"Puntajes de la validación cruzada:\")\n",
    "    print(scores_2)\n",
    "    print(f\"Promedio de los puntajes con max_depth={max_depth}\",\"->\" ,round(scores_2.mean(),4))\n",
    "    print(\"----------------------------------\")\n",
    "\n",
    "#----------------------------------------------------------   \n",
    "# El índice del árbol con mayor exactitud\n",
    "best_tree_index_2 = np.argmax(scor_2)\n",
    "#----------------------------------------------------------\n",
    "\n",
    "#----------------------------------------------------------\n",
    "# Se imprime los hiperparámetros del árbol con mayor precisión\n",
    "print(\"Los hiperparámetros del árbol con mayor precisión son:\")\n",
    "print(\"max_depth:\", max_depths[best_tree_index_2])\n",
    "print(\"criterion: entropy\")\n",
    "print(\"splitter: best\")\n",
    "print(\"random_state: 123\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Incluya en el notebook una tabla con el accuracy para los 10 árboles del punto anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.746429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>0.708929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>0.680357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>35</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>40</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>45</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>50</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_depth  accuracy\n",
       "0          5  0.746429\n",
       "1         10  0.708929\n",
       "2         15  0.680357\n",
       "3         20  0.687500\n",
       "4         25  0.687500\n",
       "5         30  0.687500\n",
       "6         35  0.687500\n",
       "7         40  0.687500\n",
       "8         45  0.687500\n",
       "9         50  0.687500"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#----------------------------------------------------------\n",
    "#Libreria pandas\n",
    "#----------------------------------------------------------\n",
    "import pandas as pd\n",
    "\n",
    "# Mostrar el accuracy de los 10 arboles construidos \n",
    "accuracies_2 = pd.DataFrame({\"max_depth\": range(5, 55, 5), \"accuracy\": scor_2})\n",
    "display(accuracies_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Repita el mismo procedimiento del punto 4 usando como hiperparámetros criterion=entropy, splitter=random, random_state=123, y variando el hiperparámetro max_depth desde 5 hasta 50 con incrementos de 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "Puntajes de la validación cruzada:\n",
      "[0.76785714 0.76785714 0.70535714 0.74107143 0.73214286]\n",
      "Promedio de los puntajes con max_depth=5 -> 0.7429\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Puntajes de la validación cruzada:\n",
      "[0.65178571 0.75892857 0.69642857 0.6875     0.69642857]\n",
      "Promedio de los puntajes con max_depth=10 -> 0.6982\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Puntajes de la validación cruzada:\n",
      "[0.71428571 0.69642857 0.6875     0.66071429 0.70535714]\n",
      "Promedio de los puntajes con max_depth=15 -> 0.6929\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Puntajes de la validación cruzada:\n",
      "[0.66071429 0.70535714 0.66964286 0.66071429 0.625     ]\n",
      "Promedio de los puntajes con max_depth=20 -> 0.6643\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Puntajes de la validación cruzada:\n",
      "[0.66071429 0.70535714 0.66964286 0.63392857 0.625     ]\n",
      "Promedio de los puntajes con max_depth=25 -> 0.6589\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Puntajes de la validación cruzada:\n",
      "[0.66071429 0.70535714 0.66964286 0.63392857 0.625     ]\n",
      "Promedio de los puntajes con max_depth=30 -> 0.6589\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Puntajes de la validación cruzada:\n",
      "[0.66071429 0.70535714 0.66964286 0.63392857 0.625     ]\n",
      "Promedio de los puntajes con max_depth=35 -> 0.6589\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Puntajes de la validación cruzada:\n",
      "[0.66071429 0.70535714 0.66964286 0.63392857 0.625     ]\n",
      "Promedio de los puntajes con max_depth=40 -> 0.6589\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Puntajes de la validación cruzada:\n",
      "[0.66071429 0.70535714 0.66964286 0.63392857 0.625     ]\n",
      "Promedio de los puntajes con max_depth=45 -> 0.6589\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Puntajes de la validación cruzada:\n",
      "[0.66071429 0.70535714 0.66964286 0.63392857 0.625     ]\n",
      "Promedio de los puntajes con max_depth=50 -> 0.6589\n",
      "----------------------------------\n",
      "Los hiperparámetros del árbol con mayor precisión son:\n",
      "max_depth: 5\n",
      "criterion: entropy\n",
      "splitter: random\n",
      "random_state: 123\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------------------------\n",
    "#Librerias sklearn.tree y sklearn.model_selection\n",
    "#----------------------------------------------------------\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "scores_3=[]\n",
    "scor_3=[]\n",
    "decision_tree_3 = []\n",
    "accuracies_9 = []\n",
    "max_depths = range(5, 55, 5)\n",
    "\n",
    "for max_depth in max_depths: \n",
    "    model_tree_3 = DecisionTreeClassifier(criterion=\"entropy\", splitter=\"random\", max_depth=max_depth, random_state=123)\n",
    "    model_tree_3.fit(X_train, y_train)\n",
    "    accuracy_9 = accuracy_score(y_test, y_pred) \n",
    "    accuracies_9.append(accuracy_9)\n",
    "    decision_tree_3.append(model_tree_3.score(X_test, y_test))\n",
    "    scores_3 = cross_val_score(model_tree_3, X_train, y_train, cv=5,scoring='accuracy') \n",
    "    scor_3.append(scores_3.mean()) \n",
    "    print(\"----------------------------------\")\n",
    "    print(\"Puntajes de la validación cruzada:\")\n",
    "    print(scores_3)\n",
    "    print(f\"Promedio de los puntajes con max_depth={max_depth}\",\"->\" ,round(scores_3.mean(),4))\n",
    "    print(\"----------------------------------\")\n",
    "    \n",
    "#----------------------------------------------------------   \n",
    "# El índice del árbol con mayor exactitud\n",
    "best_tree_index_3 = np.argmax(scor_3)\n",
    "#----------------------------------------------------------\n",
    "\n",
    "#----------------------------------------------------------\n",
    "# Se imprime los hiperparámetros del árbol con mayor precisión\n",
    "print(\"Los hiperparámetros del árbol con mayor precisión son:\")\n",
    "print(\"max_depth:\", max_depths[best_tree_index_3])\n",
    "print(\"criterion: entropy\")\n",
    "print(\"splitter: random\")\n",
    "print(\"random_state: 123\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Incluya en el notebook una tabla con el accuracy para los 10 árboles del punto anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.742857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>0.698214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>0.692857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>0.664286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>0.658929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30</td>\n",
       "      <td>0.658929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>35</td>\n",
       "      <td>0.658929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>40</td>\n",
       "      <td>0.658929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>45</td>\n",
       "      <td>0.658929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>50</td>\n",
       "      <td>0.658929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_depth  accuracy\n",
       "0          5  0.742857\n",
       "1         10  0.698214\n",
       "2         15  0.692857\n",
       "3         20  0.664286\n",
       "4         25  0.658929\n",
       "5         30  0.658929\n",
       "6         35  0.658929\n",
       "7         40  0.658929\n",
       "8         45  0.658929\n",
       "9         50  0.658929"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#----------------------------------------------------------\n",
    "#Libreria pandas\n",
    "#----------------------------------------------------------\n",
    "import pandas as pd\n",
    "\n",
    "# Mostrar el accuracy de los 10 arboles construidos \n",
    "accuracies_3 = pd.DataFrame({\"max_depth\": range(5, 55, 5), \"accuracy\": scor_3})\n",
    "display(accuracies_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
