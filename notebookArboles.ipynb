{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arboles de decisiones para predecir si una persona sufrirá de un derrame cerebral\n",
    "1.Leer el archivo stroke.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------\n",
    "# Se importan las librerias\n",
    "#----------------------------------------------------------\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 700 entries, 0 to 699\n",
      "Data columns (total 11 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   sexo                    700 non-null    object \n",
      " 1   edad                    700 non-null    float64\n",
      " 2   hipertension            700 non-null    int64  \n",
      " 3   enfermedades_cardiacas  700 non-null    int64  \n",
      " 4   casado                  700 non-null    object \n",
      " 5   tipo_trabajo            700 non-null    object \n",
      " 6   tipo_residencia         700 non-null    object \n",
      " 7   nivel_glucosa_promedio  700 non-null    float64\n",
      " 8   indice_masa_corporal    651 non-null    float64\n",
      " 9   estado_tabaquismo       700 non-null    object \n",
      " 10  derrame_cerebral        700 non-null    int64  \n",
      "dtypes: float64(3), int64(3), object(5)\n",
      "memory usage: 60.3+ KB\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------------------------\n",
    "# Url de los datos\n",
    "#----------------------------------------------------------\n",
    "\n",
    "url = (\"https://raw.githubusercontent.com/Yurani1143/Informe_Inteligencia_Artificial/main/stroke.csv\")\n",
    "\n",
    "#----------------------------------------------------------\n",
    "# Se cargan los datos\n",
    "#----------------------------------------------------------\n",
    "datos = pd.read_csv(url, sep=\",\")\n",
    "datos.columns= [\"sexo\",\"edad\",\"hipertension\",\"enfermedades_cardiacas\",\"casado\",\"tipo_trabajo\",\"tipo_residencia\",\"nivel_glucosa_promedio\",\"indice_masa_corporal\",\"estado_tabaquismo\",\"derrame_cerebral\"]\n",
    "datos.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Seleccionar aleatoriamente el 80% del conjunto de datos para entrenar y el 20% restante para las pruebas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700 560 140\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------------------------\n",
    "# Libreria sklearn\n",
    "#----------------------------------------------------------\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "N=len(datos) # cantidad de datos\n",
    "cTrain=int(N*0.8) # 80% para entrenar y 20% para probar\n",
    "cTest=N-cTrain \n",
    "\n",
    "print(N,cTrain,cTest)# cantidad de: datos completos, datos entrenados, datos para probar\n",
    "\n",
    "train_data,test_data= sklearn.model_selection.train_test_split(datos, train_size=cTrain, test_size=cTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "700 es el número de observaciones en la base de datos\n",
    "\n",
    "560 es el 80% de las observaciones de la base de datos que se van a utilizar para entrenar los datos\n",
    "\n",
    "140 es el 20% de las observaciones de la base de datos que se van a utilizar para probar el modelo de predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(560, 11)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#----------------------------------------------------------\n",
    "# Dimensiones de los datos de entrenamiento\n",
    "#----------------------------------------------------------\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Utilizar una estrategia para normalizar los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline para los atributos categóricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------\n",
    "#Librerias sklearn\n",
    "#----------------------------------------------------------\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# 5 atributos categóricos\n",
    "cat_attribs = ['sexo','casado','tipo_trabajo','tipo_residencia','estado_tabaquismo']\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"cat_encoder\", OneHotEncoder(sparse=False))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline para los atributos númericos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 5 atributos numéricos\n",
    "num_attribs = ['edad','hipertension','enfermedades_cardiacas','nivel_glucosa_promedio','indice_masa_corporal']\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------\n",
    "#Libreria sklearn\n",
    "#----------------------------------------------------------\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "    (\"num\", num_pipeline, num_attribs),\n",
    "    (\"cat\", cat_pipeline, cat_attribs),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kevin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(560, 20)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#----------------------------------------------------------\n",
    "# Se transforman los datos entrenados \n",
    "# Variables independientes\n",
    "#----------------------------------------------------------\n",
    "X_train = full_pipeline.fit_transform(train_data)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.18996717, -0.40227568, -0.3266793 , -0.48917712, -0.65385633,\n",
       "        1.        ,  0.        ,  0.        ,  1.        ,  0.        ,\n",
       "        0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "        1.        ,  0.        ,  1.        ,  0.        ,  0.        ])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "588    0\n",
       "674    0\n",
       "646    0\n",
       "658    0\n",
       "314    0\n",
       "      ..\n",
       "563    0\n",
       "434    0\n",
       "666    0\n",
       "351    0\n",
       "613    0\n",
       "Name: derrame_cerebral, Length: 560, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#----------------------------------------------------------\n",
    "# Variable dependiente -> derrame_cerebral\n",
    "#----------------------------------------------------------\n",
    "\n",
    "y_train = train_data[\"derrame_cerebral\"]\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.30937074, -0.40227568, -0.3266793 , ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.26527256, -0.40227568, -0.3266793 , ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       [ 0.17707622,  2.48585743,  3.06110607, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       ...,\n",
       "       [ 1.10313786, -0.40227568, -0.3266793 , ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.30937074, -0.40227568,  3.06110607, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [-0.74898543, -0.40227568,  3.06110607, ...,  1.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#----------------------------------------------------------\n",
    "# Se transforman los datos de prueba \n",
    "# Variables independientes\n",
    "#--------------------------------------------------------\n",
    "X_test = full_pipeline.transform(test_data) \n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120    1\n",
       "367    0\n",
       "217    1\n",
       "107    1\n",
       "224    1\n",
       "      ..\n",
       "88     1\n",
       "129    1\n",
       "112    1\n",
       "97     1\n",
       "342    0\n",
       "Name: derrame_cerebral, Length: 140, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#----------------------------------------------------------\n",
    "# Variable dependiente -> derrame_cerebral\n",
    "#----------------------------------------------------------\n",
    "y_test = test_data[\"derrame_cerebral\"]\n",
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Configurar los hiperparámetros del árbol de decisión de la siguiente manera: criterion=gini, splitter=best,\n",
    "y random_state=123. Obtener 10 árboles de decisión que resultan de modificar el hiperparámetro\n",
    "max_depth desde 5 hasta 50 con incrementos de 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "Puntajes de la validación cruzada:\n",
      "[0.8125     0.83035714 0.75       0.76785714 0.73214286]\n",
      "Promedio de los puntajes con max_depth=5 -> 0.7786\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Puntajes de la validación cruzada:\n",
      "[0.75       0.75       0.74107143 0.73214286 0.65178571]\n",
      "Promedio de los puntajes con max_depth=10 -> 0.725\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Puntajes de la validación cruzada:\n",
      "[0.72321429 0.70535714 0.74107143 0.74107143 0.64285714]\n",
      "Promedio de los puntajes con max_depth=15 -> 0.7107\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Puntajes de la validación cruzada:\n",
      "[0.72321429 0.70535714 0.74107143 0.74107143 0.64285714]\n",
      "Promedio de los puntajes con max_depth=20 -> 0.7107\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Puntajes de la validación cruzada:\n",
      "[0.72321429 0.70535714 0.74107143 0.74107143 0.64285714]\n",
      "Promedio de los puntajes con max_depth=25 -> 0.7107\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Puntajes de la validación cruzada:\n",
      "[0.72321429 0.70535714 0.74107143 0.74107143 0.64285714]\n",
      "Promedio de los puntajes con max_depth=30 -> 0.7107\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Puntajes de la validación cruzada:\n",
      "[0.72321429 0.70535714 0.74107143 0.74107143 0.64285714]\n",
      "Promedio de los puntajes con max_depth=35 -> 0.7107\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Puntajes de la validación cruzada:\n",
      "[0.72321429 0.70535714 0.74107143 0.74107143 0.64285714]\n",
      "Promedio de los puntajes con max_depth=40 -> 0.7107\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Puntajes de la validación cruzada:\n",
      "[0.72321429 0.70535714 0.74107143 0.74107143 0.64285714]\n",
      "Promedio de los puntajes con max_depth=45 -> 0.7107\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Puntajes de la validación cruzada:\n",
      "[0.72321429 0.70535714 0.74107143 0.74107143 0.64285714]\n",
      "Promedio de los puntajes con max_depth=50 -> 0.7107\n",
      "----------------------------------\n",
      "Los hiperparámetros del árbol con mayor precisión son:\n",
      "max_depth: 5\n",
      "criterion: gini\n",
      "splitter: best\n",
      "random_state: 123\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------------------------\n",
    "#Librerias sklearn.tree y sklearn.model_selection\n",
    "#----------------------------------------------------------\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "scores=[]\n",
    "scor=[]\n",
    "decision_tree = []\n",
    "accuracies = []\n",
    "max_depths = range(5, 55, 5)\n",
    "\n",
    "for max_depth in max_depths: \n",
    "    model_tree = DecisionTreeClassifier(criterion=\"gini\", splitter=\"best\", max_depth=max_depth, random_state=123)\n",
    "    model_tree.fit(X_train, y_train)\n",
    "    y_pred = model_tree.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred) \n",
    "    accuracies.append(accuracy)\n",
    "    decision_tree.append(model_tree.score(X_test, y_test))\n",
    "    scores = cross_val_score(model_tree, X_train, y_train, cv=5,scoring='accuracy') \n",
    "    scor.append(scores.mean()) \n",
    "    print(\"----------------------------------\")\n",
    "    print(\"Puntajes de la validación cruzada:\")\n",
    "    print(scores)\n",
    "    print(f\"Promedio de los puntajes con max_depth={max_depth}\",\"->\" ,round(scores.mean(),4))\n",
    "    print(\"----------------------------------\")\n",
    "    \n",
    "#----------------------------------------------------------   \n",
    "# El índice del árbol con mayor exactitud\n",
    "best_tree_index = np.argmax(scor)\n",
    "#----------------------------------------------------------\n",
    "\n",
    "#----------------------------------------------------------\n",
    "# Se imprime los hiperparámetros del árbol con mayor precisión\n",
    "print(\"Los hiperparámetros del árbol con mayor precisión son:\")\n",
    "print(\"max_depth:\", max_depths[best_tree_index])\n",
    "print(\"criterion: gini\")\n",
    "print(\"splitter: best\")\n",
    "print(\"random_state: 123\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Incluya en el notebook una tabla con el accuracy para los 10 árboles del punto anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.778571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>0.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>0.710714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>0.710714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>0.710714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30</td>\n",
       "      <td>0.710714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>35</td>\n",
       "      <td>0.710714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>40</td>\n",
       "      <td>0.710714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>45</td>\n",
       "      <td>0.710714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>50</td>\n",
       "      <td>0.710714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_depth  accuracy\n",
       "0          5  0.778571\n",
       "1         10  0.725000\n",
       "2         15  0.710714\n",
       "3         20  0.710714\n",
       "4         25  0.710714\n",
       "5         30  0.710714\n",
       "6         35  0.710714\n",
       "7         40  0.710714\n",
       "8         45  0.710714\n",
       "9         50  0.710714"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#----------------------------------------------------------\n",
    "#Libreria pandas\n",
    "#----------------------------------------------------------\n",
    "import pandas as pd\n",
    "\n",
    "# Mostrar el accuracy de los 10 arboles construidos\n",
    "accuracies_CV = pd.DataFrame({\"max_depth\": range(5, 55, 5), \"accuracy\": scor})\n",
    "display(accuracies_CV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Repita el mismo procedimiento del punto 4 usando como hiperparámetros criterion=entropy, splitter=best,\n",
    "random_state=123, y variando el hiperparámetro max_depth desde 5 hasta 50 con incrementos de 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "Puntajes de la validación cruzada:\n",
      "[0.74107143 0.78571429 0.78571429 0.72321429 0.73214286]\n",
      "Promedio de los puntajes con max_depth=10 -> 0.7536\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Puntajes de la validación cruzada:\n",
      "[0.75       0.75892857 0.75892857 0.6875     0.67857143]\n",
      "Promedio de los puntajes con max_depth=20 -> 0.7268\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Puntajes de la validación cruzada:\n",
      "[0.75       0.75892857 0.75892857 0.6875     0.67857143]\n",
      "Promedio de los puntajes con max_depth=30 -> 0.7268\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Puntajes de la validación cruzada:\n",
      "[0.75       0.75892857 0.75892857 0.6875     0.67857143]\n",
      "Promedio de los puntajes con max_depth=40 -> 0.7268\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Puntajes de la validación cruzada:\n",
      "[0.75       0.75892857 0.75892857 0.6875     0.67857143]\n",
      "Promedio de los puntajes con max_depth=50 -> 0.7268\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Puntajes de la validación cruzada:\n",
      "[0.75       0.75892857 0.75892857 0.6875     0.67857143]\n",
      "Promedio de los puntajes con max_depth=60 -> 0.7268\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Puntajes de la validación cruzada:\n",
      "[0.75       0.75892857 0.75892857 0.6875     0.67857143]\n",
      "Promedio de los puntajes con max_depth=70 -> 0.7268\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Puntajes de la validación cruzada:\n",
      "[0.75       0.75892857 0.75892857 0.6875     0.67857143]\n",
      "Promedio de los puntajes con max_depth=80 -> 0.7268\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Puntajes de la validación cruzada:\n",
      "[0.75       0.75892857 0.75892857 0.6875     0.67857143]\n",
      "Promedio de los puntajes con max_depth=90 -> 0.7268\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Puntajes de la validación cruzada:\n",
      "[0.75       0.75892857 0.75892857 0.6875     0.67857143]\n",
      "Promedio de los puntajes con max_depth=100 -> 0.7268\n",
      "----------------------------------\n",
      "Los hiperparámetros del árbol con mayor precisión son:\n",
      "max_depth: 10\n",
      "criterion: entropy\n",
      "splitter: best\n",
      "random_state: 123\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------------------------\n",
    "#Librerias sklearn.tree y sklearn.model_selection\n",
    "#----------------------------------------------------------\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "scores_2=[]\n",
    "scor_2 =[]\n",
    "decision_tree_2 = []\n",
    "accuracies_p7= []\n",
    "max_depths = range(5, 55, 5)\n",
    "\n",
    "for max_depth in max_depths: \n",
    "    model_tree_2 = DecisionTreeClassifier(criterion=\"entropy\", splitter=\"best\", max_depth=max_depth, random_state=123)\n",
    "    model_tree_2.fit(X_train, y_train)\n",
    "    accuracy_7 = accuracy_score(y_test, y_pred) # exactitud de cada árbol\n",
    "    accuracies_p7.append(accuracy_7)\n",
    "    decision_tree_2.append(model_tree_2.score(X_test, y_test))\n",
    "    scores_2 = cross_val_score(model_tree_2, X_train, y_train, cv=5,scoring='accuracy')\n",
    "    scor_2.append(scores_2.mean()) # promedio de los scores\n",
    "    print(\"----------------------------------\")\n",
    "    print(\"Puntajes de la validación cruzada:\")\n",
    "    print(scores_2)\n",
    "    print(f\"Promedio de los puntajes con max_depth={max_depth}\",\"->\" ,round(scores_2.mean(),4))\n",
    "    print(\"----------------------------------\")\n",
    "\n",
    "#----------------------------------------------------------   \n",
    "# El índice del árbol con mayor exactitud\n",
    "best_tree_index_2 = np.argmax(scor_2)\n",
    "#----------------------------------------------------------\n",
    "\n",
    "#----------------------------------------------------------\n",
    "# Se imprime los hiperparámetros del árbol con mayor precisión\n",
    "print(\"Los hiperparámetros del árbol con mayor precisión son:\")\n",
    "print(\"max_depth:\", max_depths[best_tree_index_2])\n",
    "print(\"criterion: entropy\")\n",
    "print(\"splitter: best\")\n",
    "print(\"random_state: 123\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Incluya en el notebook una tabla con el accuracy para los 10 árboles del punto anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>0.753571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>0.726786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>0.726786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>0.726786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>0.726786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60</td>\n",
       "      <td>0.726786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>70</td>\n",
       "      <td>0.726786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>80</td>\n",
       "      <td>0.726786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>90</td>\n",
       "      <td>0.726786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100</td>\n",
       "      <td>0.726786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_depth  accuracy\n",
       "0         10  0.753571\n",
       "1         20  0.726786\n",
       "2         30  0.726786\n",
       "3         40  0.726786\n",
       "4         50  0.726786\n",
       "5         60  0.726786\n",
       "6         70  0.726786\n",
       "7         80  0.726786\n",
       "8         90  0.726786\n",
       "9        100  0.726786"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#----------------------------------------------------------\n",
    "#Libreria pandas\n",
    "#----------------------------------------------------------\n",
    "import pandas as pd\n",
    "\n",
    "# Mostrar el accuracy de los 10 arboles construidos \n",
    "accuracies_2 = pd.DataFrame({\"max_depth\": range(10, 110, 10), \"accuracy\": scor_2})\n",
    "display(accuracies_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
